{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def month_dates(start, end):\n",
    "    f = lambda date: date.month + 12 * date.year\n",
    "\n",
    "    res = []\n",
    "    for tot_m in range(f(start)-1, f(end)):\n",
    "        y, m = divmod(tot_m, 12)\n",
    "        res.append(str(y) + '/' + '%02d' % (m+1))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date(article):\n",
    "    \"\"\"\n",
    "    This method returns the date of the article\n",
    "    \"\"\"\n",
    "    str_date = article.find('entity').find('meta').find('issue_date').text\n",
    "    return datetime.strptime(str_date, '%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_articles_in_file(file, start_date, end_date):\n",
    "    articles = []  \n",
    "    for article in file.iter('article'):\n",
    "        if article.find('entity') is not None:\n",
    "            a = ''\n",
    "            date = get_date(article)\n",
    "            if start_date <= date <= end_date:\n",
    "                for entity in article.iter('entity'):\n",
    "                    a += entity.findtext('full_text') + ' '\n",
    "                articles.append(date.strftime('%d/%m/%Y') + ' ' + a)\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_articles(path, start_date, end_date):\n",
    "    articles = []\n",
    "    for m_date in month_dates(start_date, end_date):\n",
    "        try:\n",
    "            file = etree.parse(path + m_date + '.xml')\n",
    "            articles.append(get_articles_in_file(file, start_date, end_date))\n",
    "        except (FileNotFoundError, IOError):\n",
    "            pass\n",
    "    return [a for file in articles for a in file]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/mbanga/Desktop/JDG/'\n",
    "start_date =  datetime(1990, 1, 1)\n",
    "end_date = datetime(1990, 1, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles = get_articles(path, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3434"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fr_core_news_sm\n",
    "import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = fr_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def punct_space(token):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens\n",
    "    that are pure punctuaiton or whitespace\n",
    "    \"\"\"\n",
    "    \n",
    "    return token.is_punct or token.is_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_french(word):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens that\n",
    "    are not french words.\n",
    "    \"\"\"\n",
    "    d = enchant.Dict('fr_FR')\n",
    "    return d.check(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatized_corpus(corpus):\n",
    "    \"\"\"\n",
    "    generator function to use spaCy to parse articles,\n",
    "    lemmatize the text, and yield sentences\n",
    "    \"\"\"\n",
    "    j = 0\n",
    "    i = 0\n",
    "    for parsed_article in nlp.pipe(corpus, \n",
    "                                   batch_size=50, n_threads=7):\n",
    "        \n",
    "        date = parsed_article[0].text + ' '\n",
    "        yield date + u' '.join([token.lemma_ for token in parsed_article\n",
    "                             if not punct_space(token) and is_french(token.text) and not token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Takes too long\n",
    "lemmatized_articles = []\n",
    "for lemmatized in lemmatized_corpus(articles[:300]):\n",
    "    lemmatized_articles.append(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "#import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = lemmatized_articles\n",
    "# learn the dictionnary by iterating over all of the articles\n",
    "dico = Dictionary([article.split() for article in corpus])\n",
    "\n",
    "# filter tokens that are very rare or too common from\n",
    "# the dictionary \n",
    "dico.filter_extremes(no_below=10, no_above=0.4)\n",
    "\n",
    "# reassign integer lda\n",
    "dico.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_generator(corpus):\n",
    "    \"\"\"\n",
    "    generator function to read articles from a file\n",
    "    and yield a bag-of-words representation\n",
    "    \"\"\"\n",
    "    for article in corpus:\n",
    "        yield dico.doc2bow(article.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate bag-of-word representations for\n",
    "# all reviews and save them as a matrix\n",
    "project_path = '/home/mbanga/Epfl/AppliedDataAnalysis/ADA2017_GroupWork/Project/'\n",
    "MmCorpus.serialize(os.path.join(project_path, 'corpus.mm'),\n",
    "                                bow_generator(corpus))\n",
    "\n",
    "bow_corpus = MmCorpus(os.path.join(project_path, 'corpus.mm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_filepath = os.path.join(project_path, 'lda_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 0 == 1:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "\n",
    "        # workers => sets the parallelism, and should be\n",
    "        # set to your number of physical cores minus one\n",
    "        lda = LdaMulticore(bow_corpus,\n",
    "                           num_topics=40,\n",
    "                           id2word=dico,\n",
    "                           workers=4)\n",
    "        \n",
    "        lda.save(lda_model_filepath)\n",
    "\n",
    "#load the finished LDA model from disk\n",
    "lda = LdaMulticore.load(lda_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_topic(topic_number, topn=25):\n",
    "    \"\"\"\n",
    "    accept a user-supplied topic number and\n",
    "    print out a formatted list of the top terms\n",
    "    \"\"\"\n",
    "    \n",
    "    print(u'{:20} {}'.format(u'term', u'frequency') + u'\\n')\n",
    "    \n",
    "    for term, frequency in lda.show_topic(topic_number, topn=25):\n",
    "        print(u'{:20} {:.3f}'.format(term, round(frequency, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                 frequency\n",
      "\n",
      "pays                 0.017\n",
      "dollar               0.017\n",
      "mardi                0.016\n",
      "économique           0.014\n",
      "ministre             0.012\n",
      "aider                0.011\n",
      "janvier              0.011\n",
      "marcher              0.011\n",
      "vouloir              0.011\n",
      "prix                 0.010\n",
      "américain            0.010\n",
      "2                    0.010\n",
      "mois                 0.010\n",
      "plan                 0.009\n",
      "décembre             0.009\n",
      "officiel             0.009\n",
      "présider             0.009\n",
      "placer               0.009\n",
      "vol                  0.009\n",
      "sur                  0.008\n",
      "se                   0.008\n",
      "lundi                0.008\n",
      "annoncer             0.007\n",
      "4                    0.007\n",
      "en                   0.007\n"
     ]
    }
   ],
   "source": [
    "explore_topic(topic_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
