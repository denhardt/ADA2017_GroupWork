%
% File acl2014.tex
%
% Contact: giovanni.colavizza@epfl.ch
%%
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl2014}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}

\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{Name of your project}

\author{First Author \\
  {\tt email@domain} \\\And
  Second Author \\
  {\tt email@domain} \\\And
Third Author \\
{\tt email@domain} \\}

\date{}

\begin{document}
%%\maketitle
\begin{abstract}
  This document contains the instructions for preparing a report for ADA 2017. The document itself conforms to its own specifications, and is therefore an example of
  what your manuscript should look like. This document is based on the ACL 2014 paper format.
\end{abstract}

\section{Credits}


In the scope of this project our focus lies on written political articles in newspapers.
We are willing to assess the diversity of subjects submitted for votations to Swiss residents over
the last 200 years. We essentially want to classify political articles in order to identify trends,
distributions, densities or patterns among others over the decades. Therefore, we seek to analyse 
"Le Temps digital archives and data". This dataset consists of articles representing two centuries
of informations provided by two newspapers, namely 'Le journal de Gèneve' and 'La Gazette de Lausanne'.
These are ancestors of today well-known Swiss newspaper 'Le Temps' whose publications are written in
the French language.
\\
\\
This document has been adapted from the instructions for earlier ACL
proceedings, including those for ACL-2012 by Maggie Li and Michael
White, those from ACL-2010 by Jing-Shing Chang and Philipp Koehn,
those for ACL-2008 by Johanna D. Moore, Simone Teufel, James Allan,
and Sadaoki Furui, those for ACL-2005 by Hwee Tou Ng and Kemal
Oflazer, those for ACL-2002 by Eugene Charniak and Dekang Lin, and
earlier ACL and EACL formats. Those versions were written by several
people, including John Chen, Henry S. Thompson and Donald
Walker. Additional elements were taken from the formatting
instructions of the {\em International Joint Conference on Artificial
  Intelligence}.

\section{Introduction}

Due to its federal constitution Switzerland Confederation has forged itself
a solid reputation as one of the world most democratic country. The land is praised by observers and often
regarded as a model to follow. One key specificity of this state relies undoubtedly in the voting frequency.
Indeed Swiss citizens are regularly called to the polls. This aspect among others constitutes one fundamental
argument showing the 'democraticity' of the country.
\\
Votations, as they are named in the country, can be initiate by any citizen. Those votations can take place at
three different layers of the federal confederation, namely communal, cantonal or federal. Communal votations
are reserved for swiss residents inside a given commune. The same apply for cantonal votations where eligible citizen
must reside in the canton. Finally, federal votations concern all citizen in the country. This system, often
depicted as highly democratic, allow any citizen under some conditions to submit a votation to its fellow citizens.
\\
We want to challenge this polished reputation acquired over the years by gaining some insights into the various
subjects that have been addressed. 

\section{Project Goal}

In the scope of this project our focus lies on written political articles in newspapers. We are willing to assess 
the diversity of subjects proposed to votations to Swiss residents over the last 200 years. We essentially
want to classify political articles in order to identify trends, distributions, densities or patterns among 
others over the decades. This approach should allow us to gain valuable insight into concerns that underlie Swiss
political flow. 

\section{Dataset}

We seek to analyze "Le Temps digital archives and data". This dataset consists of articles representing two centuries of informations provided by two newspapers, namely 'Le journal de Gèneve' and 'La Gazette de Lausanne'. These are ancestors of today well-known Swiss newspaper 'Le Temps' whose publications are written in the French language.

The dataset at hand is very well organized. It is easy to navigate and find articles for any given time
period as publications are gathered with respect to their release month. Hence for each newspaper all articles published during a specific month of a given year are all stored in the same file. The data structure used in each of those files is xml.

Unfortunately some texts are unreadable as they contain a bunch of symbols or special characters. This observation mostly arises in old publications. This may be caused by the scanner, used to create the digital dataset, not adapted for those fonts. Or the archive being in a seriously damaged state. As an example, the following articles issued on February 1798:\\
\\
\textit{[...] JLEfauteuil c \$ t vacc'ant, et l'Assemblée s'ôccûpé * de la nomination d'un nouveau Président. Une immense majoritS y rappelle le C. Glayre " J'a * vois" besoin de forces [...]}\\
\\
Specifically the dataset consists of 4'335 xml files for a total of () articles. The period of time covered by those articles ranges from February 1798 to February 1998.

\section{Librabries}

We use differrent libraries
\section{Data preparation}

Naturally we apply tools related to the field of natural language processing to acquire our results. More
precisely we are interested in topic modeling using unsupervised learning. It has been essential to develop
a sensitive pipeline to improve the performance of the algorithm. Therefore we have modeled this pipeline into x different stages that we detail in subsequent section: data retrieval, data reduction, data cleaning and data processing.
\\
Due to its performances and the variety of implementations available through libraries we decide to use Latent Dirichlet Allocation (LDA). 
\subsection{data retrieval}

Our first task is to extract the articles from the xml files to store them in an array. The array data structure makes it easier to manipulate whether for access, write or process using the different
libraries. For each article in the files we save only the text and the date of publication.\\
It is important to mention here that articles inside the xml structure do not consistently respond the natural classification by theme as we may except. As an example let's consider the following publication issued on 04 September 1993:\\

\textit{\textbf{QUOTIDIENNES JUSTICE} Cadres du bâtiment acquittés Le Tribunal correctionnel de Lausanne a acquitté jeudi deux anciens cadres [...] \textbf{CONJONCTURE} Vaud toujours malade La marche des affaires de l'industrie vaudoise est anémique. L'entrée des commandes [...]\textbf{VOTATIONS} Deux oui et trois non libéraux Réunis à Lausanne, les délégués du Parti libéral vaudois ont pris position sur les cinq objets soumis à la votation populaire des 26 et 27 septembre prochains. [...] \textbf{PAYSANS DE MONTAGNE} Aide du gouvernement Face à la grogne suscitée chez les paysans de montagne [...]}\\

The entire text is considered a single entity inside the corresponding xml file altough we can clearly discriminate four different topics merely related to each others, namely 'Quotidiennes de Justice', 'Conjoncture', 'Votation' and 'Paysan de montagne'. This remark motivates a choice we explain in the next subsection.

\subsection{data reduction}

In order to discriminate articles related to votations from others we take a very simple yet sensitive approach. We argue that it is very unlikely that any publication related to Swiss votations does not contain at least one word in a set of predefined words. We mention here those words we consider as strongly related to votations: (). Those words are obtained based on our personal intuition. Of course, One can argue about the accuracy of such a method. We may certainly generate false positive or discard relevant articles. Yet the sample size we obtain with this first process appears to be large enough to capture the information we are interested in. For the unique year 1990 this approach allows us to extract more than 3000 publications.
\\
Furthermore, we make an assumption that reduces the length of any given publication related to votations. As mentionned earlier the goal is to identify and classify votation subjects. By visual inspection, we notice this information is usually closed to one of the keywords showed earlier. 
Let's consider the following extract of a publication issued on 04 September 1993:\\
\\
\textit{VOTATIONS Deux oui et trois non libéraux Réunis à Lausanne, les délégués du Parti libéral vaudois ont pris position sur les cinq objets soumis à la \textbf{votation} populaire des 26 et 27 septembre prochains. C'est ainsi qu'ils ont accepté le rattachement du district de Laufon à Bâle-Campagne et l'arrêté fédéral urgent en matière \textbf{d'assurance-maladie}. En revanche, l'arrêté fédéral contre l'usage abusif \textbf{d'armes} et l'initative \textbf{« Pour un jour de Fête national férié »} n'ont pas trouvé grâce à leurs yeux. Pas plus d'ailleurs que l'arrêté fédéral urgent en matière \textbf{d'assurance chômage}, jugé trop coûteux pour l'économie.}\\

This extract is part of the article presented in the previous subsection. It represents approximately twenty percent of the original in terms of number of characters. Yet it is more than enough to visually capture the subjects, highlighted in bold, of the votations. More importantly, the remaining part of the article does not provide any insight for the information we are looking for. We can even argue that it is pure noise that needs to be discarded. As a consequence we retain only sentences containing one of our defined keywords together with its closest neighboors, namely the preceding and following sentences. Again we are aware that this filtering method may discard relevant information. More importantly, this assumption may reveal disastruous for our results if it appears to be erroneous.


\subsection{Data cleaning}

At this stage we have stored in an array articles related to votations. Our objective is now to pre-process those publication before running the unsupervised learning method. The pipeline we use for this task can be summarized by the following schema
\\
\\
\textit{remove non French words $\rightarrow$ lemmatize $\rightarrow$ remove stop words $\rightarrow$ remove digits}
\\

To remove non French words we use a dictionary proposed by the NLTK library. The lemmatization step is resolved through Spacy lemmatizer. Spacy library also proposes functionalities to easily detect and remove stop words and digits. All those actions put together return a cleaner corpus that can be processed more efficiently at later stages.

\section{Data processing}

The pre-processing stages described in the previous section can now be exploited to derive results. As mentioned earlier the task we are interested in is named topic modeling. The problem constraints forces us to use an unsupervised learning method for clustering known as Latent Dirichlet Allocation (LDA). This choice is motivated by discussions with pairs and practical experiment results observed in the literature.
Based on observations, other clustering methods such as K-means or DBSCAN don't appear to be interesting enough alternatives. 

\subsection{Latent Dirichlet allocation}

According to Wikipedia, latent Dirichlet allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar. 
From a practical point of view, LDA represents documents as mixtures of topics that spit out words with certain probabilities. Documents are interpreted using the bag-of-words representation. LDA then tries to backtrack from the documents to find a set of topics that are likely to have generated the collection.

\label{sect:pdf}

For the production of the electronic manuscript you must use Adobe's
Portable Document Format (PDF). PDF files are usually produced from
\LaTeX\ using the \textit{pdflatex} command. If your version of
\LaTeX\ produces Postscript files, you can convert these into PDF
using \textit{ps2pdf} or \textit{dvipdf}. On Windows, you can also use
Adobe Distiller to generate PDF.

Please make sure that your PDF file includes all the necessary fonts
(especially tree diagrams, symbols, and fonts with Asian
characters). When you print or create the PDF file, there is usually
an option in your printer setup to include none, all or just
non-standard fonts.  Please make sure that you select the option of
including ALL the fonts. \textbf{Before sending it, test your PDF by
  printing it from a computer different from the one where it was
  created.} Moreover, some word processors may generate very large PDF
files, where each page is rendered as an image. Such images may
reproduce poorly. In this case, try alternative ways to obtain the
PDF. One way on some systems is to install a driver for a postscript
printer, send your document to the printer specifying ``Output to a
file'', then convert the file to PDF.

It is of utmost importance to specify the \textbf{A4 format} (21 cm
x 29.7 cm) when formatting the report. When working with
{\tt dvips}, for instance, one should specify {\tt -t a4}.

Print-outs of the PDF file on A4 report should be identical to the
hardcopy version.


\subsection{Layout}
\label{ssec:layout}

Format manuscripts two columns to a page, in the manner these
instructions are formatted. The exact dimensions for a page on A4
report are:

\begin{itemize}
\item Left and right margins: 2.5 cm
\item Top margin: 2.5 cm
\item Bottom margin: 2.5 cm
\item Column width: 7.7 cm
\item Column height: 24.7 cm
\item Gap between columns: 0.6 cm
\end{itemize}

\noindent Papers should not be submitted on any other report size, no exceptions.


\subsection{Fonts}

For reasons of uniformity, Adobe's {\bf Times Roman} font should be
used. In \LaTeX2e{} this is accomplished by putting

\begin{quote}
\begin{verbatim}
\usepackage{times}
\usepackage{latexsym}
\end{verbatim}
\end{quote}
in the preamble. If Times Roman is unavailable, use {\bf Computer
  Modern Roman} (\LaTeX2e{}'s default).  Note that the latter is about
  10\% less dense than Adobe's Times Roman font.


\begin{table}[h]
\begin{center}
\begin{tabular}{|l|rl|}
\hline \bf Type of Text & \bf Font Size & \bf Style \\ \hline
report title & 15 pt & bold \\
author names & 12 pt & bold \\
the word ``Abstract'' & 12 pt & bold \\
section titles & 12 pt & bold \\
document text & 11 pt  &\\
captions & 11 pt & \\
abstract text & 10 pt & \\
bibliography & 10 pt & \\
footnotes & 9 pt & \\
\hline
\end{tabular}
\end{center}
\caption{\label{font-table} Font guide.}
\end{table}

\subsection{The First Page}
\label{ssec:first}

Center the title and author's name(s) across both
columns. Do not use footnotes for affiliations. Use the
two-column format only when you begin the abstract.

{\bf Title}: Place the title centered at the top of the first page, in
a 15-point bold font. (For a complete guide to font sizes and styles,
see Table~\ref{font-table}) Long titles should be typed on two lines
without a blank line intervening. Approximately, put the title at 2.5
cm from the top of the page, followed by a blank line, then the
author's names(s) on the following line. Do not
use only initials for given names (middle initials are allowed). Do
not format surnames in all capitals (e.g., use ``Schlangen'' not
``SCHLANGEN'').  Do not format title and section headings in all
capitals as well except for proper names (such as ``BLEU'') that are
conventionally in all capitals. Start the body of the first page 7.5 cm from the top of the
page.

{\bf Abstract}: Type the abstract at the beginning of the first
column. The width of the abstract text should be smaller than the
width of the columns for the text in the body of the report by about
0.6 cm on each side. Center the word {\bf Abstract} in a 12 point bold
font above the body of the abstract. The abstract should be a concise
summary of the general thesis and conclusions of the report. It should
be no longer than 150 words. The abstract text should be in 10 point font.

{\bf Text}: Begin typing the main body of the text immediately after
the abstract, observing the two-column format as shown in 
the present document. Do not include page numbers.

{\bf Indent} when starting a new paragraph. Use 11 points for text and 
subsection headings, 12 points for section headings and 15 points for
the title. 

\subsection{Sections}

{\bf Headings}: Type and label section and subsection headings in the
style shown on the present document.  Use numbered sections (Arabic
numerals) in order to facilitate cross references. Number subsections
with the section number and the subsection number separated by a dot,
in Arabic numerals. Do not number subsubsections.

{\bf Citations}: Citations within the text appear in parentheses
as~\cite{Gusfield:97} or, if the author's name appears in the text
%%itself, as Gusfield~\shortcite{Gusfield:97}.  Append lowercase letters
to the year in cases of ambiguity.  Treat double authors as
in~\cite{Aho:72}, but write as in~\cite{Chandra:81} when more than two
authors are involved. Collapse multiple citations as
in~\cite{Gusfield:97,Aho:72}. Also refrain from using full citations
as sentence constituents. We suggest that instead of
\begin{quote}
  ``\cite{Gusfield:97} showed that ...''
\end{quote}
you use
\begin{quote}
%%``Gusfield \shortcite{Gusfield:97}   showed that ...''
\end{quote}

If you are using the provided \LaTeX{} and Bib\TeX{} style files, you
can use the command \verb|\newcite| to get ``author (year)'' citations.

\textbf{Please do not use anonymous citations} and do not include
acknowledgements when submitting your reports..

\textbf{References}: Gather the full set of references together under
the heading {\bf References}. Arrange the references alphabetically
by first author, rather than by order of occurrence in the text.
Provide as complete a citation as possible, using a consistent format,
such as the one for {\em Computational Linguistics\/} or the one in the 
{\em Publication Manual of the American 
Psychological Association\/}~\cite{APA:83}.  Use of full names for
authors rather than initials is preferred.  A list of abbreviations
for common computer science journals can be found in the ACM 
{\em Computing Reviews\/}~\cite{ACM:83}.

\subsection{Footnotes}

{\bf Footnotes}: Put footnotes at the bottom of the page and use 9
points text. They may be numbered or referred to by asterisks or other
symbols.\footnote{This is how a footnote should appear.} Footnotes
should be separated from the text by a line.\footnote{Note the line
separating the footnotes from the text.}

\subsection{Graphics}

{\bf Illustrations}: Place figures, tables, and photographs in the
report near where they are first discussed, rather than at the end, if
possible.  Wide illustrations may run across both columns.

{\bf Captions}: Provide a caption for every illustration; number each one
sequentially in the form:  ``Figure 1. Caption of the Figure.'' ``Table 1.
Caption of the Table.''  Type the captions of the figures and 
tables below the body, using 11 point text.

\begin{thebibliography}{}

\bibitem[\protect\citename{Aho and Ullman}1972]{Aho:72}
Alfred~V. Aho and Jeffrey~D. Ullman.
\newblock 1972.
\newblock {\em The Theory of Parsing, Translation and Compiling}, volume~1.
\newblock Prentice-{Hall}, Englewood Cliffs, NJ.

\bibitem[\protect\citename{{American Psychological Association}}1983]{APA:83}
{American Psychological Association}.
\newblock 1983.
\newblock {\em Publications Manual}.
\newblock American Psychological Association, Washington, DC.

\bibitem[\protect\citename{{Association for Computing Machinery}}1983]{ACM:83}
{Association for Computing Machinery}.
\newblock 1983.
\newblock {\em Computing Reviews}, 24(11):503--512.

\bibitem[\protect\citename{Chandra \bgroup et al.\egroup }1981]{Chandra:81}
Ashok~K. Chandra, Dexter~C. Kozen, and Larry~J. Stockmeyer.
\newblock 1981.
\newblock Alternation.
\newblock {\em Journal of the Association for Computing Machinery},
  28(1):114--133.

\bibitem[\protect\citename{Gusfield}1997]{Gusfield:97}
Dan Gusfield.
\newblock 1997.
\newblock {\em Algorithms on Strings, Trees and Sequences}.
\newblock Cambridge University Press, Cambridge, UK.

\end{thebibliography}

\end{document}
