{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Applied ML\n",
    "\n",
    "We are going to build a classifier of news to directly assign them to 20 news categories. Note that the pipeline that you will build in this exercise could be of great help during your project if you plan to work with text!\n",
    "\n",
    "1. Load the 20newsgroup dataset. It is, again, a classic dataset that can directly be loaded using sklearn ([link](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html)).  \n",
    "[TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf), short for term frequency–inverse document frequency, is of great help when if comes to compute textual features. Indeed, it gives more importance to terms that are more specific to the considered articles (TF) but reduces the importance of terms that are very frequent in the entire corpus (IDF). Compute TF-IDF features for every article using [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Then, split your dataset into a training, a testing and a validation set (10% for validation and 10% for testing). Each observation should be paired with its corresponding label (the article category).\n",
    "\n",
    "\n",
    "2. Train a random forest on your training set. Try to fine-tune the parameters of your predictor on your validation set using a simple grid search on the number of estimator \"n_estimators\" and the max depth of the trees \"max_depth\". Then, display a confusion matrix of your classification pipeline. Lastly, once you assessed your model, inspect the `feature_importances_` attribute of your random forest and discuss the obtained results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV ,StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We fix a seed for the rest of the code\n",
    "seed = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We load the \"20newsgroup\" dataset\n",
    "ng = fetch_20newsgroups(subset = 'all')\n",
    "\n",
    "#Extract the features\n",
    "x = ng.data\n",
    "#Extract the targets \n",
    "y = ng.target\n",
    "#Extract the names of the targets\n",
    "names = ng.target_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We split our dataset in 4 subsets.\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.1, random_state=3, stratify = y)\n",
    "\n",
    "#Creatingc the vectorizer in order to compute the TF_IDF.\n",
    "vect_tf = TfidfVectorizer().fit(x_train)\n",
    "#TF_IDF for the training set.\n",
    "x_train = vect_tf.transform(x_train)\n",
    "#TF_IDF for the testing set.\n",
    "x_test =  vect_tf.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have splited our dataset, let us set the model and train it on the training set and check the accuracy of our prediction over the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65888594164456238"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We set the model.\n",
    "alg = RandomForestClassifier()\n",
    "#Training.\n",
    "alg.fit(x_train,y_train)\n",
    "#Prediction.\n",
    "pred_y = alg.predict(x_test)\n",
    "#We calculate our accuracy.\n",
    "score = accuracy_score(pred_y,y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we want to go and try to tune the parameter in order to make better prediction.For that we will do a simple grid search on the number of estimator \"n_estimators\" and the max depth of the trees \"max_depth\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 42 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done 420 out of 420 | elapsed: 10.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=1, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'max_depth': range(1, 30, 5), 'n_estimators': range(1, 70, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We set the model.\n",
    "alg = RandomForestClassifier()\n",
    "\n",
    "#We give an initial value to the parameters we want to play on.\n",
    "n_estimators = 70\n",
    "max_depth = 30\n",
    "\n",
    "#We also set a range of variation that we want our parameter to take\n",
    "n_estimators = range(1,n_estimators,10)\n",
    "max_depth = range(1,max_depth,5)\n",
    "\n",
    "#We create a list of the parameters we want to tune.\n",
    "tuned_parameters = {\n",
    "    'n_estimators':n_estimators,\n",
    "    'max_depth':max_depth\n",
    "}\n",
    "\n",
    "\n",
    "#We define how many fold we want to use for the cross validation.\n",
    "k = 10\n",
    "\n",
    "#We set the cross-validation\n",
    "cross_fold = StratifiedKFold(10,random_state=seed,shuffle=True)\n",
    "\n",
    "#We set the number of cores that we want to dedicate to the grid search so we can parallelize the task\n",
    "num_cores = 4\n",
    "\n",
    "#We initiate a grid and use grid search to find the optimal parameters for our model and we refit the model at the end with the obtained parameters.\n",
    "best_alg = GridSearchCV(alg,tuned_parameters,cv=cross_fold,scoring='accuracy',n_jobs=num_cores, refit=True,verbose=1)\n",
    "\n",
    "best_alg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now that we obtained the optimal parameters thanks to our grid search we use them to get our new prediction.\n",
    "opti_alg  = best_alg.best_estimator_\n",
    "\n",
    "#Predition over the testing set.\n",
    "pred_y = opti_alg.predict(x_test)\n",
    "\n",
    "#We calculate our new accuracy.\n",
    "score = accuracy_score(pred_y,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New accuracy with the model trained with optimal parameters: 0.761803713528\n"
     ]
    }
   ],
   "source": [
    "print('New accuracy with the model trained with optimal parameters:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.353790</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.064265</td>\n",
       "      <td>0.064396</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 1}</td>\n",
       "      <td>42</td>\n",
       "      <td>0.078638</td>\n",
       "      <td>0.076948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053846</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.060427</td>\n",
       "      <td>0.058207</td>\n",
       "      <td>0.070665</td>\n",
       "      <td>0.070629</td>\n",
       "      <td>0.039886</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>0.009817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.471916</td>\n",
       "      <td>0.047363</td>\n",
       "      <td>0.131773</td>\n",
       "      <td>0.134098</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 11}</td>\n",
       "      <td>39</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.119486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137278</td>\n",
       "      <td>0.136009</td>\n",
       "      <td>0.114336</td>\n",
       "      <td>0.119230</td>\n",
       "      <td>0.142518</td>\n",
       "      <td>0.146364</td>\n",
       "      <td>0.043997</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>0.009991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.795412</td>\n",
       "      <td>0.102072</td>\n",
       "      <td>0.177053</td>\n",
       "      <td>0.179876</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 21}</td>\n",
       "      <td>37</td>\n",
       "      <td>0.188380</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171006</td>\n",
       "      <td>0.180407</td>\n",
       "      <td>0.169431</td>\n",
       "      <td>0.165783</td>\n",
       "      <td>0.179929</td>\n",
       "      <td>0.189697</td>\n",
       "      <td>0.165067</td>\n",
       "      <td>0.022584</td>\n",
       "      <td>0.016151</td>\n",
       "      <td>0.017185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.907049</td>\n",
       "      <td>0.171338</td>\n",
       "      <td>0.217794</td>\n",
       "      <td>0.221714</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 31}</td>\n",
       "      <td>34</td>\n",
       "      <td>0.225939</td>\n",
       "      <td>0.225732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206509</td>\n",
       "      <td>0.216620</td>\n",
       "      <td>0.216232</td>\n",
       "      <td>0.214496</td>\n",
       "      <td>0.204869</td>\n",
       "      <td>0.214898</td>\n",
       "      <td>0.112115</td>\n",
       "      <td>0.107800</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>0.018187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.032803</td>\n",
       "      <td>0.238960</td>\n",
       "      <td>0.252756</td>\n",
       "      <td>0.259945</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>{'max_depth': 1, 'n_estimators': 41}</td>\n",
       "      <td>33</td>\n",
       "      <td>0.251174</td>\n",
       "      <td>0.247558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269822</td>\n",
       "      <td>0.262000</td>\n",
       "      <td>0.260071</td>\n",
       "      <td>0.267400</td>\n",
       "      <td>0.252375</td>\n",
       "      <td>0.275512</td>\n",
       "      <td>0.139822</td>\n",
       "      <td>0.073155</td>\n",
       "      <td>0.024063</td>\n",
       "      <td>0.022804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.353790         0.007488         0.064265          0.064396   \n",
       "1       0.471916         0.047363         0.131773          0.134098   \n",
       "2       0.795412         0.102072         0.177053          0.179876   \n",
       "3       0.907049         0.171338         0.217794          0.221714   \n",
       "4       1.032803         0.238960         0.252756          0.259945   \n",
       "\n",
       "  param_max_depth param_n_estimators                                params  \\\n",
       "0               1                  1   {'max_depth': 1, 'n_estimators': 1}   \n",
       "1               1                 11  {'max_depth': 1, 'n_estimators': 11}   \n",
       "2               1                 21  {'max_depth': 1, 'n_estimators': 21}   \n",
       "3               1                 31  {'max_depth': 1, 'n_estimators': 31}   \n",
       "4               1                 41  {'max_depth': 1, 'n_estimators': 41}   \n",
       "\n",
       "   rank_test_score  split0_test_score  split0_train_score       ...         \\\n",
       "0               42           0.078638            0.076948       ...          \n",
       "1               39           0.125000            0.119486       ...          \n",
       "2               37           0.188380            0.204300       ...          \n",
       "3               34           0.225939            0.225732       ...          \n",
       "4               33           0.251174            0.247558       ...          \n",
       "\n",
       "   split7_test_score  split7_train_score  split8_test_score  \\\n",
       "0           0.053846            0.053500           0.060427   \n",
       "1           0.137278            0.136009           0.114336   \n",
       "2           0.171006            0.180407           0.169431   \n",
       "3           0.206509            0.216620           0.216232   \n",
       "4           0.269822            0.262000           0.260071   \n",
       "\n",
       "   split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
       "0            0.058207           0.070665            0.070629      0.039886   \n",
       "1            0.119230           0.142518            0.146364      0.043997   \n",
       "2            0.165783           0.179929            0.189697      0.165067   \n",
       "3            0.214496           0.204869            0.214898      0.112115   \n",
       "4            0.267400           0.252375            0.275512      0.139822   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.001624        0.009510         0.009817  \n",
       "1        0.006494        0.008932         0.009991  \n",
       "2        0.022584        0.016151         0.017185  \n",
       "3        0.107800        0.017997         0.018187  \n",
       "4        0.073155        0.024063         0.022804  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We store all the results in a dataframe\n",
    "df = pd.DataFrame(best_alg.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>17.485287</td>\n",
       "      <td>0.194268</td>\n",
       "      <td>0.771947</td>\n",
       "      <td>0.911372</td>\n",
       "      <td>26</td>\n",
       "      <td>61</td>\n",
       "      <td>{'max_depth': 26, 'n_estimators': 61}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.789906</td>\n",
       "      <td>0.918005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777515</td>\n",
       "      <td>0.91605</td>\n",
       "      <td>0.771919</td>\n",
       "      <td>0.912787</td>\n",
       "      <td>0.761283</td>\n",
       "      <td>0.905021</td>\n",
       "      <td>1.161235</td>\n",
       "      <td>0.032696</td>\n",
       "      <td>0.012539</td>\n",
       "      <td>0.004456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "41      17.485287         0.194268         0.771947          0.911372   \n",
       "\n",
       "   param_max_depth param_n_estimators                                 params  \\\n",
       "41              26                 61  {'max_depth': 26, 'n_estimators': 61}   \n",
       "\n",
       "    rank_test_score  split0_test_score  split0_train_score       ...         \\\n",
       "41                1           0.789906            0.918005       ...          \n",
       "\n",
       "    split7_test_score  split7_train_score  split8_test_score  \\\n",
       "41           0.777515             0.91605           0.771919   \n",
       "\n",
       "    split8_train_score  split9_test_score  split9_train_score  std_fit_time  \\\n",
       "41            0.912787           0.761283            0.905021      1.161235   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "41        0.032696        0.012539         0.004456  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We extract the row for which the rank_test_score ==1\n",
    "df_one = df[df['rank_test_score']==1]\n",
    "df_one.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We create our confusion matrix using the dataframe we extracted before.\n",
    "matrix = confusion_matrix(y_test,pred_y)\n",
    "df_conf = pd.DataFrame(matrix, index = names, columns = names)\n",
    "df_conf = df_conf.div(df_conf.sum(axis=1),axis=0)\n",
    "#We set the window size\n",
    "plt.figure(figsize=(20,7))\n",
    "#We create the heatmap using our dataframe\n",
    "sns.heatmap(df_conf, square=True, linecolor='w',linewidths=2,annot=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
