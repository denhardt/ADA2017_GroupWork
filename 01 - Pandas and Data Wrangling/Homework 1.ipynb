{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/robin/GIT/ADA2017-Tutorials/02 - Intro to Pandas/Data\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = '/home/robin/GIT/ADA2017-Tutorials/02 - Intro to Pandas/Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas.\n",
    "print(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "\n",
    "# Method to concat all the reports files for each country in a single dataframe\n",
    "\n",
    "def concat_files(path,date_str):\n",
    "    the_files = glob.glob(path +\"/*.csv\")\n",
    "    data_frame = pd.DataFrame()\n",
    "    for x in the_files:\n",
    "        df_temp = pd.read_csv(x,parse_dates=[date_str])\n",
    "        data_frame = pd.concat([data_frame,df_temp])\n",
    "    return data_frame\n",
    "\n",
    "# Method to select all the rows matching the 'wanted' argument\n",
    "def select_rows(df,reference,wanted):\n",
    "    return df.loc[df[reference] == wanted]\n",
    "\n",
    "# Method to add a Month column\n",
    "def add_month(df):\n",
    "    copy_df = df.copy()\n",
    "    months = [calendar.month_name[x.month] for x in copy_df.Date]\n",
    "    copy_df['Month'] = months\n",
    "    return copy_df\n",
    "\n",
    "# Method to calculate the average number of new cases per month\n",
    "def calculate_avg_new_cases(df,months):\n",
    "    avg_cases = np.zeros(len(months))\n",
    "    for i in range(len(months)):\n",
    "        temp = select_rows(df,'Month',months[i]).Total_new_cases.values.astype(float) \n",
    "        if(len(temp) < 2 ): # if less than two points, assign NaN\n",
    "            avg_cases[i] = np.nan\n",
    "        else: # Otherwise sum/number\n",
    "            avg_cases[i] = temp.sum()/temp.shape[0]\n",
    "    return avg_cases  \n",
    "\n",
    "# Method to calculate the average number of deaths per month\n",
    "def calculate_avg_new_deaths(df,months):\n",
    "    avg_cases = np.zeros(len(months))\n",
    "    for i in range(len(months)):\n",
    "        temp = select_rows(df,'Month',months[i]) # selecting relevant month\n",
    "        temp = temp.reset_index()\n",
    "        delta_t = temp['Date'].loc[len(temp)-1] - temp['Date'].loc[0] # calculate time-span of data\n",
    "        temp = temp.Total_new_deaths.values.astype(float) # extracting array of floats\n",
    "        if(temp.shape[0]<2):\n",
    "            avg_cases[i] = np.nan\n",
    "        elif(temp[len(temp)-1]-temp[0] > 0):   # if there is a difference between 1st/last time point\n",
    "            avg_cases[i] = (temp[len(temp)-1]-temp[0])/delta_t.days\n",
    "        else: \n",
    "            avg_cases[i] = (temp[len(temp)-2]-temp[0])/delta_t.days\n",
    "    return avg_cases   \n",
    "\n",
    "# Method to handle Sierra Leon and Liberia data\n",
    "def handle_data(df,desc1,desc2,desc3,new_total):\n",
    "    sl_1 = select_rows(df,'Description',desc1)\n",
    "    sl_2 = select_rows(df,'Description',desc2)\n",
    "    sl_3 = select_rows(df,'Description',desc3)\n",
    "    new_cases_registered =  [int(a) + int(b) + int(c) for a,b,c in zip(sl_1.Totals,sl_2.Totals,sl_3.Totals)]\n",
    "    sl_1[new_total] = new_cases_registered\n",
    "    sl_1 = sl_1[['Date',new_total]]\n",
    "    #sl_1 = add_month(sl_1,'Date')\n",
    "    return sl_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-1641768596b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create Guinea DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mguinea_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA_FOLDER\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/ebola/guinea_data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mg_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguinea_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Shape of Guinea DF:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-fb17d248df6a>\u001b[0m in \u001b[0;36mconcat_files\u001b[0;34m(path, date_str)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconcat_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdate_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mthe_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\"/*.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdata_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdf_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Create Guinea DF\n",
    "guinea_folder = DATA_FOLDER + '/ebola/guinea_data/'\n",
    "g_df = concat_files(guinea_folder,'Date')\n",
    "print('Shape of Guinea DF:', g_df.shape)\n",
    "\n",
    "# We can check all unique descriptions in order to choose what \n",
    "# to base our calculations on as well as to be sure not to miss anything\n",
    "print(g_df['Description'].unique())\n",
    "\n",
    "# We can then see which descriptors appear to be the most complete,\n",
    "# in this case it seems using one of the total deaths descriptors\n",
    "# is the only sensible option, we'll take the confirmed+probables+suspects\n",
    "# in order to be most complete, and probably overestimating\n",
    "print(g_df.loc[g_df['Description']=='Total deaths of probables'].shape)\n",
    "print(g_df.loc[g_df['Description']=='Total deaths of confirmed'].shape)\n",
    "print(g_df.loc[g_df['Description']=='Total deaths (confirmed + probables + suspects)'].shape)\n",
    "print(g_df.loc[g_df['Description']=='New deaths registered'].shape)\n",
    "print(g_df.loc[g_df['Description']=='New deaths registered today'].shape)\n",
    "print(g_df.loc[g_df['Description']=='New deaths registered today (probables)'].shape)\n",
    "print(g_df.loc[g_df['Description']=='New deaths registered today (suspects)'].shape)\n",
    "g_df.loc[g_df['Description']=='Total deaths (confirmed + probables + suspects)'][['Date','Description','Totals']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We only keep the columns of interest\n",
    "g_df = g_df[['Date', 'Description', 'Totals']]\n",
    "\n",
    "# We select the rows that we need in order to calculate our values\n",
    "g_new_cases = select_rows(g_df,'Description','Total new cases registered so far')\n",
    "g_new_deaths = select_rows(g_df,'Description','Total deaths (confirmed + probables + suspects)')\n",
    "g_new_deaths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handling the new Dataframes\n",
    "g_new_cases = g_new_cases[['Date','Totals']]\n",
    "g_new_cases.columns = ['Date','Total_new_cases']\n",
    "\n",
    "g_new_deaths = g_new_deaths[['Date','Totals']]\n",
    "g_new_deaths.columns = ['Date','Total_new_deaths']\n",
    "\n",
    "# We merge the 2 of them to obtain the new cases and the deaths for Guinea\n",
    "guinea_df = pd.merge(g_new_cases,g_new_deaths)\n",
    "guinea_df['Country'] = 'Guinea'\n",
    "guinea_df = guinea_df[['Country','Date','Total_new_cases','Total_new_deaths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_months = add_month(guinea_df)\n",
    "g_months.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = select_rows(g_months,'Month','September')\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating the daily average per month of new cases and deaths for Guinea\n",
    "months = ['August','September','October']\n",
    "g_results_deaths = calculate_avg_new_deaths(g_months,months)\n",
    "print(g_results_deaths)\n",
    "g_results_cases = calculate_avg_new_cases(g_months,months)\n",
    "g_results_cases\n",
    "\n",
    "# NaN values is for the months were we dont have enough data to make an average,\n",
    "# in this case there is only one data point for October, so we chose to exclude it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the Sierra Leone DataFrame\n",
    "sl_folder = DATA_FOLDER + '/ebola/sl_data/'\n",
    "sl_df = concat_files(sl_folder,'date')\n",
    "sl_df[['date' , 'variable' , 'National']]\n",
    "\n",
    "# We only keep the columns of interest \n",
    "sl_df = sl_df[['date','variable','National']]\n",
    "sl_df.columns = ['Date' , 'Description' , 'Totals']\n",
    "sl_df = sl_df.fillna(0)\n",
    "\n",
    "# Creating dataframes for new cases and new deaths\n",
    "sl_new_cases = handle_data(sl_df,'new_confirmed','new_probable','new_suspected','Total_new_cases')\n",
    "sl_new_cases1 = sl_new_cases.loc[sl_new_cases['Total_new_cases'] > 0]\n",
    "sl_new_deaths = handle_data(sl_df,'death_confirmed','death_probable','death_suspected','Total_new_deaths')\n",
    "sl_new_deaths1 = sl_new_deaths.loc[sl_new_deaths['Total_new_deaths'] > 0]\n",
    "\n",
    "# Forming the Sierra Leon DataFrame\n",
    "sierra_leon_df = pd.merge(sl_new_cases,sl_new_deaths)\n",
    "sierra_leon_df['Country'] = 'Sierra Leone'\n",
    "sl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating the daily average per month of new cases and deaths for Sierra Leon\n",
    "months = ['August','September','October','November','December']\n",
    "sl_results_deaths = calculate_avg_new_deaths(add_month(sl_new_deaths1,),months)\n",
    "sl_results_deaths\n",
    "sl_results_cases = calculate_avg_new_cases(add_month(sl_new_cases1,),months)\n",
    "sl_results_cases\n",
    "sl_results_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the Liberia DataFrame\n",
    "lib_folder = DATA_FOLDER + '/ebola/liberia_data/'\n",
    "lib_df = concat_files(lib_folder,'Date')\n",
    "\n",
    "# We only keep the columns of interest \n",
    "lib_df = lib_df[['Date','Variable','National']]\n",
    "lib_df.columns = ['Date' , 'Description' , 'Totals']\n",
    "lib_df = lib_df.fillna(0)\n",
    "lib_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating dataframes for new cases and new deaths\n",
    "lib_new_cases = handle_data(lib_df,'New Case/s (Suspected)','New Case/s (Probable)','New Case/s (Probable)','Total_new_cases')\n",
    "lib_new_cases1 = lib_new_cases.loc[lib_new_cases['Total_new_cases'] > 0]\n",
    "lib_new_deaths = handle_data(lib_df,'Total death/s in confirmed cases','Total death/s in probable cases','Total death/s in suspected cases','Total_new_deaths')\n",
    "lib_new_deaths1 = lib_new_deaths.loc[lib_new_deaths['Total_new_deaths'] > 0]\n",
    "lib_new_cases1\n",
    "lib_new_deaths1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forming the Sierra Leon DataFrame\n",
    "liberia_df = pd.merge(lib_new_cases,lib_new_deaths)\n",
    "liberia_df['Country'] = 'Liberia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating the daily average per month of new cases and deaths for Liberia\n",
    "months = ['June','July','August','September','October','November','December']\n",
    "lib_results_deaths = calculate_avg_new_deaths(add_month(lib_new_deaths1,),months)\n",
    "lib_results_deaths\n",
    "lib_results_cases = calculate_avg_new_cases(add_month(lib_new_cases1,),months)\n",
    "lib_results_cases\n",
    "#lib_results_deaths\n",
    "#liberia_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.read_excel(DATA_FOLDER+'/titanic.xls', sheetname='titanic', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Describe the type and the value range of each attribute. \n",
    "\n",
    "# We assume that we can describe the value range of each attribute\n",
    "# only if it's a numerical type\n",
    "\n",
    "types = df.dtypes\n",
    "value_range = df._get_numeric_data().apply(lambda x: (x.min(), x.max()))\n",
    "\n",
    "types.index.name = 'Attribute'\n",
    "types.columns = 'Type'\n",
    "\n",
    "value_range.index.name = 'Attribute'\n",
    "value_range.columns = 'Range'\n",
    "\n",
    "res = pd.concat(dict(Range=value_range, Type=types), axis=1).fillna('-')\n",
    "res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Indicate and transform the attributes that can be Categorical.\n",
    "\n",
    "# By visual inspection we can argue that the following columns could be\n",
    "# categorical : 'pclass', 'survived', 'sex', 'sibsp', 'parch', 'embarked'\n",
    "#\n",
    "# We assumed that for an attribute to be categorical it should have \n",
    "# <= 10 distinct elements. (NaN is not considered as a distinct value)\n",
    "\n",
    "\n",
    "\n",
    "categories = pd.Series([v for v in df.columns if len(df[v].unique()) < 10 ])\n",
    "\n",
    "print('Attributes to be made Categorical:\\n\\n', categories)\n",
    "for i in categories:\n",
    "    df[i] = df[i].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Plot a histogram for the travel class attribute\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "hist_plot = df.pclass.value_counts().plot(kind='bar')\n",
    "hist_plot.set_title('Travel Class')\n",
    "hist_plot.set_xlabel('Class')\n",
    "hist_plot.set_ylabel('Passengers')\n",
    "np.sum(df.pclass.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Plot a histogram for the embarkation port attribute\n",
    "%matplotlib inline\n",
    "\n",
    "nb_ports = df['embarked'].describe()['unique']\n",
    "df.embarked.unique()\n",
    "\n",
    "hist_plot = df.embarked.value_counts().plot(kind='bar')\n",
    "hist_plot.set_title('Embarkation port')\n",
    "hist_plot.set_xlabel('Port')\n",
    "hist_plot.set_ylabel('Passengers')\n",
    "sum(df.embarked.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Plot a histogram for the sex attribute\n",
    "%matplotlib inline\n",
    "\n",
    "hist_plot = df.sex.value_counts().plot(kind='bar')\n",
    "hist_plot.set_title('Sex')\n",
    "hist_plot.set_xlabel('Sex')\n",
    "hist_plot.set_ylabel('Passengers')\n",
    "np.sum(df.sex.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Plot a histogram for the age attribute\n",
    "\n",
    "\n",
    "nb_bins = np.ceil(df.age.max()/10).astype('int')\n",
    "hist_plot = df.age.hist(bins=nb_bins, grid=False, xlabelsize=11, ylabelsize=11, figsize=(10, 6))\n",
    "hist_plot.set_title('Age')\n",
    "hist_plot.set_xlabel('Ages')\n",
    "hist_plot.set_ylabel('Passengers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Calculate the proportion of passengers by cabin floor. \n",
    "# Present your results in a pie chart.\n",
    "\n",
    "# We assumed that the information on the cabin floor is available \n",
    "# in the column 'cabin' where the letter indicates the floor.\n",
    "# the number that follows indicates a specific cabin on that floor.\n",
    "\n",
    "# Unfortunately, this column is also filled with NaN's values.\n",
    "# For this statistic we won't try guessing the cabin floor for \n",
    "# passenger where the data is not provided. Our analysis relies\n",
    "# only on values that are already in the dataset.\n",
    "\n",
    "tot = df.cabin.describe()['count']\n",
    "\n",
    "temp = df.cabin.dropna(axis=0).apply(lambda x: str(x)[:1])\n",
    "\n",
    "D = {}\n",
    "for v in temp:\n",
    "    if not v in D:\n",
    "        D[v] = 1\n",
    "    else:\n",
    "        D[v] += 1\n",
    "\n",
    "\n",
    "labels = list(D.keys())\n",
    "values = list(D.values())\n",
    "\n",
    "\n",
    "plt.pie(values, labels=labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: For each travel class, calculate the proportion of the\n",
    "# passengers that survived. Present your results in pie charts.\n",
    "\n",
    "# The pie chart represents only passengers that survived. Each region\n",
    "# on the chart is the proportion of the passengers in the class\n",
    "# that survived among all survivors.\n",
    "\n",
    "\n",
    "tot = df.survived.describe()['count']\n",
    "\n",
    "class_tot = (df.groupby('pclass').survived.describe())['count']\n",
    "pclass_survived = df.groupby(['pclass', 'survived']).survived.describe()\n",
    "pclass_survived = (pclass_survived[pclass_survived['top'] == 1])['freq']\n",
    "pclass_survived = pclass_survived.reset_index('survived').drop('survived', axis=1)\n",
    "stats = pd.concat([class_tot, pclass_survived], axis=1)\n",
    "prop = (stats['freq'] / stats['count'])*100\n",
    "\n",
    "l = df.set_index('pclass').index.categories\n",
    "plt.pie(list(prop), labels=list(l))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Calculate the proportion of the passengers that survived \n",
    "# by travel class and sex. Present your results in a single histogram.\n",
    "\n",
    "class_tot = (df.groupby(['pclass', 'sex']).survived.describe())['count']\n",
    "survived = df.groupby(['pclass', 'sex', 'survived']).survived.describe()\n",
    "survived = (survived[survived['top'] == 1])['freq']\n",
    "survived = survived.reset_index('survived').drop('survived', axis=1)\n",
    "stats = pd.concat([class_tot, survived], axis=1)\n",
    "prop = (stats['freq'] / stats['count'])*100\n",
    "\n",
    "prop.unstack(level=1).plot(kind='bar', subplots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question: Create 2 equally populated age categories and calculate \n",
    "# survival proportions by age category, travel class and sex. Present\n",
    "# your results in a DataFrame with unique index.\n",
    "\n",
    "# Our analysis is based only on passengers that have a valid 'age'\n",
    "# field. The field is considered valid only if the value is not a NaN.\n",
    "# For this statistic we won't try guessing the passenger age when \n",
    "# the data is not provided.\n",
    "\n",
    "# We create our 2 equally populated categories as follow:\n",
    "# 1. We order the passengers by age in ascending order\n",
    "# 2. We drop from the table passengers with invalid 'age' value\n",
    "# 3. We separate the resulting dataframe in two with the cut\n",
    "#    point being half way down the table\n",
    "\n",
    "# The stats are then computed for each age category separately before \n",
    "# concatenating both resulting tables\n",
    "\n",
    "# 1.\n",
    "df.sort_values(['age'], axis=0, inplace=True)\n",
    "# 2.\n",
    "df.age.dropna(axis=0, inplace=True)\n",
    "# 3.\n",
    "mid = int(np.floor(len(df)/2))\n",
    "cat1 = df[:mid]\n",
    "cat2 = df[mid:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival proportions by age category, travel class and sex\n",
    "# Age Category #1\n",
    "\n",
    "class_tot = (cat1.groupby(['age', 'pclass', 'sex']).survived.describe())['count']\n",
    "survived = cat1.groupby(['age', 'pclass', 'sex', 'survived']).survived.describe()\n",
    "survived = (survived[survived['top'] == 1])['freq']\n",
    "survived = survived.reset_index('survived').drop('survived', axis=1)\n",
    "stats = pd.concat([class_tot, survived], axis=1).fillna(0)\n",
    "stats.columns = ['total', 'survivors']\n",
    "\n",
    "s1 = stats.groupby(['pclass', 'sex']).sum()\n",
    "\n",
    "s1['age'] = 'Younger'\n",
    "s1.set_index('age', append=True, inplace=True)\n",
    "s1 = s1.reorder_levels(['age', 'pclass', 'sex'])\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival proportions by age category, travel class and sex\n",
    "# Age Category #2\n",
    "\n",
    "class_tot = (cat2.groupby(['age', 'pclass', 'sex']).survived.describe())['count']\n",
    "survived = cat2.groupby(['age', 'pclass', 'sex', 'survived']).survived.describe()\n",
    "survived = (survived[survived['top'] == 1])['freq']\n",
    "survived = survived.reset_index('survived').drop('survived', axis=1)\n",
    "stats = pd.concat([class_tot, survived], axis=1).fillna(0)\n",
    "stats.columns = ['total', 'survivors']\n",
    "\n",
    "s2 = stats.groupby(['pclass', 'sex']).sum()\n",
    "\n",
    "s2['age'] = 'Older'\n",
    "s2.set_index('age', append=True, inplace=True)\n",
    "s2 = s2.reorder_levels(['age', 'pclass', 'sex'])\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival proportions by age category, travel class and sex\n",
    "df = pd.concat([s1, s2], axis=0)\n",
    "df['proportion'] = (df['survivors'] / df['total'])*100\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
